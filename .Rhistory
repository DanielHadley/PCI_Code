my.df <- read.csv("K:/Somerstat/Common/Data/2014 StreetStat/PCI.csv")
my.df$est.years <- 79*(2.71828^(-9.37879/(100-my.df$OCI)^0.48))
plot(my.df$est.years, my.df$OCI)
last.paved <- 2012 - my.df$est.years
hist(my.df$last.paved)
my.df$last.paved <- 2012 - my.df$est.years
hist(my.df$last.paved)
curtatone <- my.df[which(my.df$last.paved>2013),]
curtatone <- my.df[which(my.df$last.paved > 2003),]
View(curtatone)
really.old <- my.df[which(my.df$last.paved < 1990),]
View(really.old)
really.old <- my.df[which(my.df$last.paved < 1989),]
View(really.old)
my.df$est.years <- 79*(2.71828^(-9.37879/(100-my.df$OCI)^0.48))
plot(my.df$est.years, my.df$OCI)
hist(my.df$OCI)
library(ggplot2)
my.theme <-
theme(plot.background = element_blank(), # Remove background
panel.grid.major = element_blank(), # Remove gridlines
panel.grid.minor = element_blank(), # Remove more gridlines
panel.border = element_blank(), # Remove border
panel.background = element_blank(), # Remove more background
axis.ticks = element_blank(), # Remove axis ticks
axis.text=element_text(size=24), # Enlarge axis text font
axis.title=element_text(size=26), # Enlarge axis title font
plot.title=element_text(size=42, hjust=0) # Enlarge, left-align title
,axis.text.x = element_text(angle=60, hjust = 1) # Uncomment if X-axis unreadable
)
p <- qplot(OCI, weight = Length, data = my.df, geom = "histogram", alpha=I(.7), main="Activity by Length", ylab="Col2 Count")
p + my.theme
p <- qplot(OCI, weight = Length, data = my.df, geom = "bar", alpha=I(.7), main="PCI by Length", ylab="Col2 Count")
p + my.theme
p <- qplot(OCI, weight = Length, data = my.df, fill=Treatmentb, geom = "bar", alpha=I(.7), main="PCI by Length", ylab="Col2 Count")
p + my.theme
p <- qplot(OCI, weight = Length, data = my.df, colour = "black", fill=Treatmentb, geom = "bar", main="PCI by Length", ylab="Col2 Count")
p + my.theme
p <- qplot(OCI, weight = Length, data = my.df, colour = white, fill=Treatmentb, geom = "bar", main="PCI by Length", ylab="Col2 Count")
p + my.theme
p <- qplot(OCI, weight = Length, data = my.df, colour = "white", fill=Treatmentb, geom = "bar", main="PCI by Length", ylab="Col2 Count")
p + my.theme
hist(my.df$last.paved)
plot(my.df$est.years, my.df$OCI)
View(my.df)
my.df$sq.ft <- my.df$PavementWi x my.df$Length
my.df$sq.ft <- my.df$PavementWi * my.df$Length
my.df$sq.yd <- my.df$sq.ft * 0.111111
p <- qplot(OCI, weight = sq.ft, data = my.df, colour = "white", fill=Treatmentb, geom = "bar", main="PCI by Length", ylab="Length of Roadway")
p + my.theme
View(my.df)
appetizer.solution <- local (
function (target) {
app <- c(2.15, 2.75, 3.35, 3.55, 4.20, 5.80)
r <- 2L
repeat {
c <- gtools::combinations(length(app), r=r, v=app, repeats.allowed=TRUE)
s <- rowSums(c)
if ( all(s > target) ) {
print("No solution found")
break
}
x <- which( abs(s-target) < 1e-4 )
if ( length(x) > 0L ) {
cat("Solution found: ", c[x,], "\n")
break
}
r <- r + 1L
}
})
appetizer.solution <- local (
function (target) {
app <- c(2.15, 2.75, 3.35, 3.55, 4.20, 5.80)
r <- 2L
repeat {
c <- gtools::combinations(length(app), r=r, v=app, repeats.allowed=TRUE)
s <- rowSums(c)
if ( all(s > target) ) {
print("No solution found")
break
}
x <- which( abs(s-target) < 1e-4 )
if ( length(x) > 0L ) {
cat("Solution found: ", c[x,], "\n")
break
}
r <- r + 1L
}
})
appetizer.solution(12)
app <- c(2.15, 2.75, 3.35, 3.55, 4.20, 5.80)
my.df <- read.csv("K:/Somerstat/Common/Data/2014 StreetStat/PCI_Code/PCI.csv")
# This code cleans and analyzes data from FST, the pavement consultant
# OCI value = PCI.  Note these scores are from November 2012.
# It models the cost and PCI degredation in order to optimize pavement decisions
# Created By Daniel Hadley
setwd("K:/Somerstat/Common/Data/2014 StreetStat/PCI_Code")
my.df <- read.csv("PCI.csv")
# Create new variables
my.df$sq.ft <- my.df$PavementWi * my.df$Length # Sq. Feet
my.df$sq.yd <- my.df$sq.ft * 0.111111 # Sq. Yards
my.df$total.pci <- my.df$sq.yd * my.df$OCI # Sum PCI
my.df$ideal.pci <- my.df$sq.yd * 95 # Ideal sum PCI
my.df$delta.pci <- my.df$ideal.pci - my.df$total.pci #Difference
my.df$delta.over.cost <- my.df$delta.pci / my.df$ExtendedCo #One cost measure
aggregate(delta.over.cost ~ PlanActivi, my.df, mean ) # Crack Seal is crazy cost efficient
aggregate(delta.over.cost ~ PlanActivi, my.df, max ) # Crack Seal is crazy cost efficient
my.df$cost.per.sq.yd <- my.df$ExtendedCo / my.df$sq.yd
# Here I model the age as a function of PCI based on the references below:
# It is an average of residential and arterial, but we can divide those later
# http://onlinepubs.trb.org/onlinepubs/conferences/2012/assetmgmt/presentations/Data-A-Ramirez-Flores-Chang-Albitres.pdf
# https://repository.tamu.edu/bitstream/handle/1969.1/ETD-TAMU-2009-05-317/DESHMUKH-THESIS.pdf?sequence=2
# http://www.mylongview.com/modules/showdocument.aspx?documentid=631
# PCI = 100 - (106/((ln(79/AGE))^(1/.48)))
my.df$est.years <- 79*(2.71828^(-9.37879/(100-my.df$OCI)^0.48))
plot(my.df$est.years, my.df$OCI)
my.df$last.paved <- 2012 - my.df$est.years
hist(my.df$last.paved) # I'm skeptical there are streets we have not paved since the 80s
# test
plot(log(my.df$ExtendedCo), my.df$OCI)
plot(my.df$delta.over.cost, my.df$OCI) # checking cost-effectiveness
# This final plot is where we see that high OCI maintenance is the most cost-effective
# Now model the cost degredation as a f(PCI) using a smooth curve
# This smooths out all of the "cliffs" from the difference maintenance bands,
# but it approximates how quickly costs escalate as a f of PCI and allows for linear optimization
####  Use the empirical distribution of PCI ####
# http://davetang.org/muse/2013/05/09/on-curve-fitting/
y = my.df$cost.per.sq.yd
x = my.df$OCI
plot(x,y)
#fit first degree polynomial equation:
fit  <- lm(y~x)
#second degree
fit2 <- lm(y~poly(x,2,raw=TRUE))
#third degree
fit3 <- lm(y~poly(x,3,raw=TRUE))
#fourth degree
fit4 <- lm(y~poly(x,4,raw=TRUE))
#generate range of 50 numbers starting from 30 and ending at 160
xx <- seq(0,160, length=50)
plot(x,y,pch=19,ylim=c(0,150))
lines(xx, predict(fit, data.frame(x=xx)), col="red")
lines(xx, predict(fit2, data.frame(x=xx)), col="green")
lines(xx, predict(fit3, data.frame(x=xx)), col="blue")
lines(xx, predict(fit4, data.frame(x=xx)), col="purple") ## This looks like the best fit
# Now model it based on the coefficients from fit4
#y=e + dx + cx^2 + bx^3 + ax^4
coef(fit4)
my.df$cost.model <- 1.351524e+02 + (1.845730e+00 * my.df$OCI) +
(-1.630135e-01 * my.df$OCI^2) +
(2.195987e-03 * my.df$OCI^3) +
(-8.857414e-06 * my.df$OCI^4)
fit <- lm(my.df$cost.model,my.df$cost.per.sq.yd)
summary(fit) # show results
# Visualize
plot(my.df$cost.model*my.df$sq.yd, my.df$cost.per.sq.yd*my.df$sq.yd)
plot(log(my.df$cost.model*my.df$sq.yd), log(my.df$cost.per.sq.yd*my.df$sq.yd))
# This code cleans and analyzes data from FST, the pavement consultant
# OCI value = PCI.  Note these scores are from November 2012.
# It models the cost and PCI degredation in order to optimize pavement decisions
# Created By Daniel Hadley
setwd("K:/Somerstat/Common/Data/2014 StreetStat/PCI_Code")
my.df <- read.csv("PCI.csv")
# Create new variables
my.df$sq.ft <- my.df$PavementWi * my.df$Length # Sq. Feet
my.df$sq.yd <- my.df$sq.ft * 0.111111 # Sq. Yards
my.df$total.pci <- my.df$sq.yd * my.df$OCI # Sum PCI
my.df$ideal.pci <- my.df$sq.yd * 95 # Ideal sum PCI
my.df$delta.pci <- my.df$ideal.pci - my.df$total.pci #Difference
my.df$delta.over.cost <- my.df$delta.pci / my.df$ExtendedCo #One cost measure
aggregate(delta.over.cost ~ PlanActivi, my.df, mean ) # Crack Seal is crazy cost efficient
aggregate(delta.over.cost ~ PlanActivi, my.df, max ) # Crack Seal is crazy cost efficient
my.df$cost.per.sq.yd <- my.df$ExtendedCo / my.df$sq.yd
my.df$est.years <- 79*(2.71828^(-9.37879/(100-my.df$OCI)^0.48))
plot(my.df$est.years, my.df$OCI)
my.df$last.paved <- 2012 - my.df$est.years
hist(my.df$last.paved) # I'm skeptical there are streets we have not paved since the 80s
# test
plot(log(my.df$ExtendedCo), my.df$OCI)
plot(my.df$delta.over.cost, my.df$OCI) # checking cost-effectiveness
# This final plot is where we see that high OCI maintenance is the most cost-effective
# First model cost as a f(PCI) using logical tests:
# this averages differences between collectors and arterials
# To see where the bands begin and end
aggregate(OCI ~ PlanActivi, my.df, mean )
aggregate(OCI ~ PlanActivi, my.df, min )
aggregate(OCI ~ PlanActivi, my.df, max )
my.df$cost.per.sq.yd.boolean <- ifelse((my.df$OCI > 67) & (my.df$OCI < 89), 1.8,
ifelse((my.df$OCI > 44) & (my.df$OCI < 67), 18.50,
ifelse((my.df$OCI > 23) & (my.df$OCI < 44), 83.50,
ifelse((my.df$OCI > 0) & (my.df$OCI < 23), 150,
ifelse(my.df$OCI > 89, 0, 360)))))
# Now model the cost degredation as a f(PCI) using a smooth curve
# This smooths out all of the "cliffs" from the difference maintenance bands,
# but it approximates how quickly costs escalate as a f of PCI and allows for linear optimization
####  Use the empirical distribution of PCI ####
# http://davetang.org/muse/2013/05/09/on-curve-fitting/
y = my.df$cost.per.sq.yd
x = my.df$OCI
plot(x,y)
#fit first degree polynomial equation:
fit  <- lm(y~x)
#second degree
fit2 <- lm(y~poly(x,2,raw=TRUE))
#third degree
fit3 <- lm(y~poly(x,3,raw=TRUE))
#fourth degree
fit4 <- lm(y~poly(x,4,raw=TRUE))
#generate range of 50 numbers starting from 30 and ending at 160
xx <- seq(0,160, length=50)
plot(x,y,pch=19,ylim=c(0,150))
lines(xx, predict(fit, data.frame(x=xx)), col="red")
lines(xx, predict(fit2, data.frame(x=xx)), col="green")
lines(xx, predict(fit3, data.frame(x=xx)), col="blue")
lines(xx, predict(fit4, data.frame(x=xx)), col="purple") ## This looks like the best fit
# Now model it based on the coefficients from fit4
#y=e + dx + cx^2 + bx^3 + ax^4
coef(fit4)
my.df$cost.model <- 1.351524e+02 + (1.845730e+00 * my.df$OCI) +
(-1.630135e-01 * my.df$OCI^2) +
(2.195987e-03 * my.df$OCI^3) +
(-8.857414e-06 * my.df$OCI^4)
fit <- lm(my.df$cost.model,my.df$cost.per.sq.yd)
summary(fit) # show results
fit <- lm(my.df$cost.model,my.df$cost.per.sq.yd)
summary(fit) # show results
plot(my.df$cost.model*my.df$sq.yd, my.df$cost.per.sq.yd*my.df$sq.yd)
plot(log(my.df$cost.model*my.df$sq.yd), log(my.df$cost.per.sq.yd*my.df$sq.yd))
#fit first degree polynomial equation:
fit  <- lm(y~x)
#second degree
fit2 <- lm(y~poly(x,2,raw=TRUE))
#third degree
fit3 <- lm(y~poly(x,3,raw=TRUE))
#fourth degree
fit4 <- lm(y~poly(x,4,raw=TRUE))
#generate range of 50 numbers starting from 30 and ending at 160
xx <- seq(0,160, length=50)
plot(x,y,pch=19,ylim=c(0,150))
lines(xx, predict(fit, data.frame(x=xx)), col="red")
lines(xx, predict(fit2, data.frame(x=xx)), col="green")
lines(xx, predict(fit3, data.frame(x=xx)), col="blue")
lines(xx, predict(fit4, data.frame(x=xx)), col="purple") ## This looks like the best fit
plot(my.df$cost.model*my.df$sq.yd, my.df$cost.per.sq.yd*my.df$sq.yd)
my.df$cost.per.sq.yd.boolean <- ifelse((my.df$OCI > 67) & (my.df$OCI < 89), 1.8,
ifelse((my.df$OCI > 44) & (my.df$OCI < 67), 18.50,
ifelse((my.df$OCI > 23) & (my.df$OCI < 44), 83.50,
ifelse((my.df$OCI > 0) & (my.df$OCI < 23), 150,
ifelse(my.df$OCI > 89, 0, 360)))))
plot(log(cost.per.sq.yd.boolean*my.df$sq.yd), log(my.df$cost.per.sq.yd*my.df$sq.yd))
plot(log(my.df$cost.per.sq.yd.boolean*my.df$sq.yd), log(my.df$cost.per.sq.yd*my.df$sq.yd))
plot(my.df$cost.per.sq.yd.boolean*my.df$sq.yd, my.df$cost.per.sq.yd*my.df$sq.yd)
dif <- my.df$cost.per.sq.yd*my.df$sq.yd - my.df$cost.per.sq.yd.boolean*my.df$sq.yd
hist(dif)
summary(dif)
my.df$dif <- my.df$cost.per.sq.yd*my.df$sq.yd - my.df$cost.per.sq.yd.boolean*my.df$sq.yd
View(my.df)
hugeDif <- my.df[ which(my.df$dif>650000 | my.df$dif < 115000), ]
View(hugeDif)
hugeDif <- my.df[ which(my.df$dif>650000 | my.df$dif < 115000), ]
hugeDif <- my.df[ which(my.df$dif>650000 | my.df$dif < -115000), ]
View(hugeDif)
aggregate(OCI ~ PlanActivi, my.df, mean )
#fit first degree polynomial equation:
fit  <- lm(y~x)
#second degree
fit2 <- lm(y~poly(x,2,raw=TRUE))
#third degree
fit3 <- lm(y~poly(x,3,raw=TRUE))
#fourth degree
fit4 <- lm(y~poly(x,4,raw=TRUE))
#generate range of 50 numbers starting from 30 and ending at 160
xx <- seq(0,160, length=50)
plot(x,y,pch=19,ylim=c(0,150))
lines(xx, predict(fit, data.frame(x=xx)), col="red")
lines(xx, predict(fit2, data.frame(x=xx)), col="green")
lines(xx, predict(fit3, data.frame(x=xx)), col="blue")
lines(xx, predict(fit4, data.frame(x=xx)), col="purple") ## This looks like the best fit
# Now model it based on the coefficients from fit4
#y=e + dx + cx^2 + bx^3 + ax^4
coef(fit4)
my.df$cost.per.sq.yd
