smoothingSpline = smooth.spline(x, y, spar=0.35)
plot(x,y)
lines(smoothingSpline)
smoothingSpline
summary(smoothingSpline)
# Fit an exponential curve
x <- c(100, 89, 95, 78, 57, 36, 18, 0) # PCI
y <- c(0.01, 0.01, 0.01, 1.8, 18.5, 83.5, 150, 150) #Cost
d <- data.frame(y, x)
x <- c(32,64,96,118,126,144,152.5,158)
y <- c(99.5,104.8,108.5,100,86,64,35.3,15)
#we will make y the response variable and x the predictor
#the response variable is usually on the y-axis
plot(x,y,pch=19)
# Fit an exponential curve
x <- c(100, 89, 95, 78, 57, 36, 18, 0) # PCI
y <- c(0.01, 0.01, 0.01, 1.8, 18.5, 83.5, 150, 150) #Cost
d <- data.frame(y, x)
#we will make y the response variable and x the predictor
#the response variable is usually on the y-axis
plot(x,y,pch=19)
#fit first degree polynomial equation:
fit  <- lm(y~x)
#second degree
fit2 <- lm(y~poly(x,2,raw=TRUE))
#third degree
fit3 <- lm(y~poly(x,3,raw=TRUE))
#fourth degree
fit4 <- lm(y~poly(x,4,raw=TRUE))
#generate range of 50 numbers starting from 30 and ending at 160
xx <- seq(30,160, length=50)
plot(x,y,pch=19,ylim=c(0,150))
lines(xx, predict(fit, data.frame(x=xx)), col="red")
lines(xx, predict(fit2, data.frame(x=xx)), col="green")
lines(xx, predict(fit3, data.frame(x=xx)), col="blue")
lines(xx, predict(fit4, data.frame(x=xx)), col="purple")
#we will make y the response variable and x the predictor
#the response variable is usually on the y-axis
plot(x,y,pch=19)
#fit first degree polynomial equation:
fit  <- lm(y~x)
#second degree
fit2 <- lm(y~poly(x,2,raw=TRUE))
#third degree
fit3 <- lm(y~poly(x,3,raw=TRUE))
#fourth degree
fit4 <- lm(y~poly(x,4,raw=TRUE))
#generate range of 50 numbers starting from 30 and ending at 160
xx <- seq(30,160, length=50)
plot(x,y,pch=19,ylim=c(0,250))
lines(xx, predict(fit, data.frame(x=xx)), col="red")
lines(xx, predict(fit2, data.frame(x=xx)), col="green")
lines(xx, predict(fit3, data.frame(x=xx)), col="blue")
lines(xx, predict(fit4, data.frame(x=xx)), col="purple")
# Fit an exponential curve
x <- c(100, 89, 95, 78, 57, 36, 18, 0) # PCI
y <- c(0.01, 0.01, 0.01, 1.8, 18.5, 83.5, 150, 150) #Cost
d <- data.frame(y, x)
fit  <- lm(y~x)
fit2 <- lm(y~poly(x,2,raw=TRUE))
fit3 <- lm(y~poly(x,3,raw=TRUE))
fit4 <- lm(y~poly(x,4,raw=TRUE))
#generate range of 50 numbers starting from 30 and ending at 160
xx <- seq(30,160, length=250)
plot(x,y,pch=19,ylim=c(0,150))
lines(xx, predict(fit, data.frame(x=xx)), col="red")
lines(xx, predict(fit2, data.frame(x=xx)), col="green")
lines(xx, predict(fit3, data.frame(x=xx)), col="blue")
lines(xx, predict(fit4, data.frame(x=xx)), col="purple")
#fit first degree polynomial equation:
fit  <- lm(y~x)
#second degree
fit2 <- lm(y~poly(x,2,raw=TRUE))
#third degree
fit3 <- lm(y~poly(x,3,raw=TRUE))
#fourth degree
fit4 <- lm(y~poly(x,4,raw=TRUE))
#generate range of 50 numbers starting from 30 and ending at 160
xx <- seq(0,160, length=50)
plot(x,y,pch=19,ylim=c(0,150))
lines(xx, predict(fit, data.frame(x=xx)), col="red")
lines(xx, predict(fit2, data.frame(x=xx)), col="green")
lines(xx, predict(fit3, data.frame(x=xx)), col="blue")
lines(xx, predict(fit4, data.frame(x=xx)), col="purple")
x <- c(100, 89, 95, 78, 57, 36, 18, 0) # PCI
y <- c(0.01, 0.01, 0.01, 1.8, 18.5, 83.5, 150, 150) #Cost
dat <- data.frame(y, x)
# a smattering of possible models... just made up on the spot
# with more effort some better candidates should be added
# a smattering of possible models...
models <- list(lm(y~x, data = dat),
lm(y~I(1/x), data=dat),
lm(y ~ log(x), data = dat),
nls(y ~ I(1/x*a) + b*x, data = dat, start = list(a = 1, b = 1)),
nls(y ~ (a + b*log(x)), data=dat, start = setNames(coef(lm(y ~ log(x), data=dat)), c("a", "b"))),
nls(y ~ I(exp(1)^(a + b * x)), data=dat, start = list(a=0,b=0)),
nls(y ~ I(1/x*a)+b, data=dat, start = list(a=1,b=1))
)
# have a quick look at the visual fit of these models
library(ggplot2)
ggplot(dat, aes(x, y)) + geom_point(size = 5) +
stat_smooth(method = "lm", formula = as.formula(models[[1]]), size = 1, se = FALSE, colour = "black") +
stat_smooth(method = "lm", formula = as.formula(models[[2]]), size = 1, se = FALSE, colour = "blue") +
stat_smooth(method = "lm", formula = as.formula(models[[3]]), size = 1, se = FALSE, colour = "yellow") +
stat_smooth(method = "nls", formula = as.formula(models[[4]]), data=dat, start = list(a=0,b=0), size = 1, se = FALSE, colour = "red") +
stat_smooth(method = "nls", formula = as.formula(models[[5]]), data=dat, start = setNames(coef(lm(y ~ log(x), data=dat)), c("a", "b")), size = 1, se = FALSE, colour = "green") +
stat_smooth(method = "nls", formula = as.formula(models[[6]]), data=dat, start = list(a=0,b=0), size = 1, se = FALSE, colour = "violet") +
stat_smooth(method = "nls", formula = as.formula(models[[7]]), data=dat, start = list(a=0,b=0), size = 1, se = FALSE, colour = "orange")
models <- list(lm(y~x, data = dat),
lm(y~I(1/x), data=dat),
lm(y ~ log(x), data = dat),
nls(y ~ I(1/x*a) + b*x, data = dat, start = list(a = 1, b = 1)),
nls(y ~ (a + b*log(x)), data=dat, start = setNames(coef(lm(y ~ log(x), data=dat)), c("a", "b"))),
nls(y ~ I(exp(1)^(a + b * x)), data=dat, start = list(a=0,b=0)),
nls(y ~ I(1/x*a)+b, data=dat, start = list(a=1,b=1))
)
x <- c(100, 89, 95, 78, 57, 36, 18, 0.01) # PCI
y <- c(0.01, 0.01, 0.01, 1.8, 18.5, 83.5, 150, 150) #Cost
dat <- data.frame(y, x)
# a smattering of possible models... just made up on the spot
# with more effort some better candidates should be added
# a smattering of possible models...
models <- list(lm(y~x, data = dat),
lm(y~I(1/x), data=dat),
lm(y ~ log(x), data = dat),
nls(y ~ I(1/x*a) + b*x, data = dat, start = list(a = 1, b = 1)),
nls(y ~ (a + b*log(x)), data=dat, start = setNames(coef(lm(y ~ log(x), data=dat)), c("a", "b"))),
nls(y ~ I(exp(1)^(a + b * x)), data=dat, start = list(a=0,b=0)),
nls(y ~ I(1/x*a)+b, data=dat, start = list(a=1,b=1))
)
# have a quick look at the visual fit of these models
library(ggplot2)
ggplot(dat, aes(x, y)) + geom_point(size = 5) +
stat_smooth(method = "lm", formula = as.formula(models[[1]]), size = 1, se = FALSE, colour = "black") +
stat_smooth(method = "lm", formula = as.formula(models[[2]]), size = 1, se = FALSE, colour = "blue") +
stat_smooth(method = "lm", formula = as.formula(models[[3]]), size = 1, se = FALSE, colour = "yellow") +
stat_smooth(method = "nls", formula = as.formula(models[[4]]), data=dat, start = list(a=0,b=0), size = 1, se = FALSE, colour = "red") +
stat_smooth(method = "nls", formula = as.formula(models[[5]]), data=dat, start = setNames(coef(lm(y ~ log(x), data=dat)), c("a", "b")), size = 1, se = FALSE, colour = "green") +
stat_smooth(method = "nls", formula = as.formula(models[[6]]), data=dat, start = list(a=0,b=0), size = 1, se = FALSE, colour = "violet") +
stat_smooth(method = "nls", formula = as.formula(models[[7]]), data=dat, start = list(a=0,b=0), size = 1, se = FALSE, colour = "orange")
models <- list(lm(y~x, data = dat),
lm(y~I(1/x), data=dat),
lm(y ~ log(x), data = dat),
nls(y ~ I(1/x*a) + b*x, data = dat, start = list(a = 1, b = 1)),
nls(y ~ (a + b*log(x)), data=dat, start = setNames(coef(lm(y ~ log(x), data=dat)), c("a", "b"))),
nls(y ~ I(exp(1)^(a + b * x)), data=dat, start = list(a=0,b=0)),
nls(y ~ I(1/x*a)+b, data=dat, start = list(a=1,b=1))
)
models <- list(lm(y~x, data = dat),
lm(y~I(1/x), data=dat),
lm(y ~ log(x), data = dat),
nls(y ~ I(1/x*a) + b*x, data = dat, start = list(a = 1, b = 1)),
nls(y ~ (a + b*log(x)), data=dat, start = setNames(coef(lm(y ~ log(x), data=dat)), c("a", "b"))),
nls(y ~ I(exp(1)^(a + b * x)), data=dat, start = list(a=0.01,b=0)),
nls(y ~ I(1/x*a)+b, data=dat, start = list(a=1,b=1))
)
models <- list(lm(y~x, data = dat),
lm(y~I(1/x), data=dat),
lm(y ~ log(x), data = dat),
nls(y ~ I(1/x*a) + b*x, data = dat, start = list(a = 1, b = 1)),
nls(y ~ (a + b*log(x)), data=dat, start = setNames(coef(lm(y ~ log(x), data=dat)), c("a", "b"))),
nls(y ~ I(1/x*a)+b, data=dat, start = list(a=1,b=1))
)
x <- c(100, 89, 95, 78, 57, 36, 18, 0.01) # PCI
y <- c(0.01, 0.01, 0.01, 1.8, 18.5, 83.5, 150, 150) #Cost
dat <- data.frame(y, x)
# a smattering of possible models... just made up on the spot
# with more effort some better candidates should be added
# a smattering of possible models...
models <- list(lm(y~x, data = dat),
lm(y~I(1/x), data=dat),
lm(y ~ log(x), data = dat),
nls(y ~ I(1/x*a) + b*x, data = dat, start = list(a = 1, b = 1)),
nls(y ~ (a + b*log(x)), data=dat, start = setNames(coef(lm(y ~ log(x), data=dat)), c("a", "b"))),
nls(y ~ I(1/x*a)+b, data=dat, start = list(a=1,b=1))
)
# have a quick look at the visual fit of these models
library(ggplot2)
ggplot(dat, aes(x, y)) + geom_point(size = 5) +
stat_smooth(method = "lm", formula = as.formula(models[[1]]), size = 1, se = FALSE, colour = "black") +
stat_smooth(method = "lm", formula = as.formula(models[[2]]), size = 1, se = FALSE, colour = "blue") +
stat_smooth(method = "lm", formula = as.formula(models[[3]]), size = 1, se = FALSE, colour = "yellow") +
stat_smooth(method = "nls", formula = as.formula(models[[4]]), data=dat, start = list(a=0,b=0), size = 1, se = FALSE, colour = "red") +
stat_smooth(method = "nls", formula = as.formula(models[[5]]), data=dat, start = setNames(coef(lm(y ~ log(x), data=dat)), c("a", "b")), size = 1, se = FALSE, colour = "green") +
stat_smooth(method = "nls", formula = as.formula(models[[6]]), data=dat, start = list(a=0,b=0), size = 1, se = FALSE, colour = "violet") +
stat_smooth(method = "nls", formula = as.formula(models[[7]]), data=dat, start = list(a=0,b=0), size = 1, se = FALSE, colour = "orange")
ggplot(dat, aes(x, y)) + geom_point(size = 5) +
stat_smooth(method = "lm", formula = as.formula(models[[1]]), size = 1, se = FALSE, colour = "black") +
stat_smooth(method = "lm", formula = as.formula(models[[2]]), size = 1, se = FALSE, colour = "blue") +
stat_smooth(method = "lm", formula = as.formula(models[[3]]), size = 1, se = FALSE, colour = "yellow") +
stat_smooth(method = "nls", formula = as.formula(models[[4]]), data=dat, start = list(a=0,b=0), size = 1, se = FALSE, colour = "red") +
stat_smooth(method = "nls", formula = as.formula(models[[5]]), data=dat, start = setNames(coef(lm(y ~ log(x), data=dat)), c("a", "b")), size = 1, se = FALSE, colour = "green") +
stat_smooth(method = "nls", formula = as.formula(models[[6]]), data=dat, start = list(a=0,b=0), size = 1, se = FALSE, colour = "violet") +
stat_smooth(method = "nls", formula = as.formula(models[[7]]), data=dat, start = list(a=0,b=0), size = 1, se = FALSE, colour = "orange")
x <- c(100, 89, 95, 78, 57, 36, 18, 0.01) # PCI
y <- c(0.01, 0.01, 0.01, 1.8, 18.5, 83.5, 150, 150) #Cost
dat <- data.frame(y, x)
# a smattering of possible models... just made up on the spot
# with more effort some better candidates should be added
# a smattering of possible models...
models <- list(lm(y~x, data = dat),
lm(y~I(1/x), data=dat),
lm(y ~ log(x), data = dat),
nls(y ~ I(1/x*a) + b*x, data = dat, start = list(a = 1, b = 1)),
nls(y ~ (a + b*log(x)), data=dat, start = setNames(coef(lm(y ~ log(x), data=dat)), c("a", "b"))),
nls(y ~ I(1/x*a)+b, data=dat, start = list(a=1,b=1))
)
# have a quick look at the visual fit of these models
library(ggplot2)
ggplot(dat, aes(x, y)) + geom_point(size = 5) +
stat_smooth(method = "lm", formula = as.formula(models[[1]]), size = 1, se = FALSE, colour = "black") +
stat_smooth(method = "lm", formula = as.formula(models[[2]]), size = 1, se = FALSE, colour = "blue") +
stat_smooth(method = "lm", formula = as.formula(models[[3]]), size = 1, se = FALSE, colour = "yellow") +
stat_smooth(method = "nls", formula = as.formula(models[[4]]), data=dat, start = list(a=0,b=0), size = 1, se = FALSE, colour = "red") +
stat_smooth(method = "nls", formula = as.formula(models[[5]]), data=dat, start = setNames(coef(lm(y ~ log(x), data=dat)), c("a", "b")), size = 1, se = FALSE, colour = "green") +
stat_smooth(method = "nls", formula = as.formula(models[[6]]), data=dat, start = list(a=0,b=0), size = 1, se = FALSE, colour = "orange")
x <- c(100, 89, 95, 78, 57, 36, 18, 0.01) # PCI
y <- c(0.01, 0.01, 0.01, 1.8, 18.5, 83.5, 150, 150) #Cost
dat <- data.frame(x, y)
# a smattering of possible models... just made up on the spot
# with more effort some better candidates should be added
# a smattering of possible models...
models <- list(lm(y~x, data = dat),
lm(y~I(1/x), data=dat),
lm(y ~ log(x), data = dat),
nls(y ~ I(1/x*a) + b*x, data = dat, start = list(a = 1, b = 1)),
nls(y ~ (a + b*log(x)), data=dat, start = setNames(coef(lm(y ~ log(x), data=dat)), c("a", "b"))),
nls(y ~ I(1/x*a)+b, data=dat, start = list(a=1,b=1))
)
# have a quick look at the visual fit of these models
library(ggplot2)
ggplot(dat, aes(x, y)) + geom_point(size = 5) +
stat_smooth(method = "lm", formula = as.formula(models[[1]]), size = 1, se = FALSE, colour = "black") +
stat_smooth(method = "lm", formula = as.formula(models[[2]]), size = 1, se = FALSE, colour = "blue") +
stat_smooth(method = "lm", formula = as.formula(models[[3]]), size = 1, se = FALSE, colour = "yellow") +
stat_smooth(method = "nls", formula = as.formula(models[[4]]), data=dat, start = list(a=0,b=0), size = 1, se = FALSE, colour = "red") +
stat_smooth(method = "nls", formula = as.formula(models[[5]]), data=dat, start = setNames(coef(lm(y ~ log(x), data=dat)), c("a", "b")), size = 1, se = FALSE, colour = "green") +
stat_smooth(method = "nls", formula = as.formula(models[[6]]), data=dat, start = list(a=0,b=0), size = 1, se = FALSE, colour = "orange")
x <- c(100, 89, 95, 78, 57, 36, 18, 0) # PCI
y <- c(0.01, 0.01, 0.01, 1.8, 18.5, 83.5, 150, 150) #Cost
d <- data.frame(y, x)
smoothingSpline = smooth.spline(x, y, spar=0.35)
plot(x,y)
lines(smoothingSpline)
summary(smoothingSpline)
plot(x, y, main = paste("spline[fun](.) through", n, "points"))
lines(spline(x, y))
lines(spline(x, y, n = 201), col = 2)
x <- c(100, 89, 95, 78, 57, 36, 18, 0.01) # PCI
y <- c(0.01, 0.01, 0.01, 1.8, 18.5, 83.5, 150, 150) #Cost
dat <- data.frame(x, y)
plot(x, y, main = paste("spline[fun](.) through", n, "points"))
lines(spline(x, y))
lines(spline(x, y, n = 201), col = 2)
x <- c(100, 89, 95, 78, 57, 36, 18, 0.01) # PCI
y <- c(0.01, 0.01, 0.01, 1.8, 18.5, 83.5, 150, 150) #Cost
dat <- data.frame(x, y)
plot(x, y, main = paste("spline[fun](.) through", 8, "points"))
lines(spline(x, y))
lines(spline(x, y, n = 201), col = 2)
y <- sin((x-0.5)*pi)
f <- splinefun(x, y)
ls(envir = environment(f))
splinecoef <- get("z", envir = environment(f))
curve(f(x), 1, 10, col = "green", lwd = 1.5)
points(splinecoef, col = "purple", cex = 2)
curve(f(x, deriv = 1), 1, 10, col = 2, lwd = 1.5)
curve(f(x, deriv = 2), 1, 10, col = 2, lwd = 1.5, n = 401)
curve(f(x, deriv = 3), 1, 10, col = 2, lwd = 1.5, n = 401)
par(op)
splinefun(x, y)
x <- c(100, 89, 95, 78, 57, 36, 18, 0.01) # PCI
y <- c(0.01, 0.01, 0.01, 1.8, 18.5, 83.5, 150, 150) #Cost
dat <- data.frame(x, y)
z <- splinefun(x, y)
z(x, y)
summary(z)
summary(z(x, y))
x <- c(100, 89, 95, 78, 57, 36, 18, 0.01) # PCI
y <- c(0.01, 0.01, 0.01, 1.8, 18.5, 83.5, 150, 150) #Cost
dat <- data.frame(x, y)
f <- splinefun(x, y)
ls(envir = environment(f))
splinecoef <- eval(expression(z), envir = environment(f))
curve(f(x), 1, 10, col = "green", lwd = 1.5)
points(splinecoef, col = "purple", cex = 2)
par(op)
f
ls(envir = environment(f))
splinecoef <- eval(expression(z), envir = environment(f))
splinecoef
f <- splinefun(x, y)
f
summary(f)
f (x, deriv = 1)
summary(f)
fit(f)
plot(f)
ls(envir = environment(f))
# Dan,
#
# See attached.  OCI value = PCI.  Note these scores are from November 2012.  You will recognize some streets have already been done - should have score of 100.  We typically freshen this data annually and do have an existing contract to update your pavement management system but are focusing our contract hours/budget towards finalizing the City's ADA Transition Plan with respect to the public right of way.
#
# I will forward you sidewalk and ramp shapes under another email.  As you will hear from Melissa, Stan, Besty Allen, and David Shapiro - as part of the City's transition plan the City needs to commit a reasonable portion of public works construction budget towards ADA improvements that entail sidewalk, ramp and APS work annually and report these ongoing improvements to the FHWA.
#
# I'm working for formulate some suggestions based on Cambridge and Boston's commitments, in the meantime you should present a visual of sidewalk/ramp conditions to the Mayor so he may start to digest this information.
#
# Thanks,
# Bill
setwd("K:/Somerstat/Common/Data/2014 StreetStat/PCI_Code")
my.df <- read.csv("PCI.csv")
# Create new variables
my.df$sq.ft <- my.df$PavementWi * my.df$Length
my.df$sq.yd <- my.df$sq.ft * 0.111111
my.df$total.pci <- my.df$sq.yd * my.df$OCI
my.df$ideal.pci <- my.df$sq.yd * 95
my.df$delta.pci <- my.df$ideal.pci - my.df$total.pci
my.df$delta.over.cost <- my.df$delta.pci / my.df$ExtendedCo
aggregate(delta.over.cost ~ PlanActivi, my.df, mean ) # Crack Seal is crazy cost efficient
hist(my.df$ExtendedCo)
summary(my.df$ExtendedCo)
plot(my.df$ExtendedCo, my.df$sq.yd)
# Now model cost as a f(PCI) using logical tests:
# this averages differences between collectors and arterials
my.df$cost.per.sy <- ifelse((my.df$OCI > 67) & (my.df$OCI < 89), 1.8,
ifelse((my.df$OCI > 44) & (my.df$OCI < 67), 18.50,
ifelse((my.df$OCI > 23) & (my.df$OCI < 44), 83.50,
ifelse((my.df$OCI > 0) & (my.df$OCI < 23), 150,
ifelse(my.df$OCI > 89, 0, 360)))))
cost <- my.df$cost.per.sy * my.df$sy
my.df$cost <- my.df$cost.per.sy * my.df$sy
my.df$cost <- my.df$cost.per.sy * my.df$sy
# Dan,
#
# See attached.  OCI value = PCI.  Note these scores are from November 2012.  You will recognize some streets have already been done - should have score of 100.  We typically freshen this data annually and do have an existing contract to update your pavement management system but are focusing our contract hours/budget towards finalizing the City's ADA Transition Plan with respect to the public right of way.
#
# I will forward you sidewalk and ramp shapes under another email.  As you will hear from Melissa, Stan, Besty Allen, and David Shapiro - as part of the City's transition plan the City needs to commit a reasonable portion of public works construction budget towards ADA improvements that entail sidewalk, ramp and APS work annually and report these ongoing improvements to the FHWA.
#
# I'm working for formulate some suggestions based on Cambridge and Boston's commitments, in the meantime you should present a visual of sidewalk/ramp conditions to the Mayor so he may start to digest this information.
#
# Thanks,
# Bill
setwd("K:/Somerstat/Common/Data/2014 StreetStat/PCI_Code")
my.df <- read.csv("PCI.csv")
# Create new variables
my.df$sq.ft <- my.df$PavementWi * my.df$Length
my.df$sq.yd <- my.df$sq.ft * 0.111111
my.df$total.pci <- my.df$sq.yd * my.df$OCI
my.df$ideal.pci <- my.df$sq.yd * 95
my.df$delta.pci <- my.df$ideal.pci - my.df$total.pci
my.df$delta.over.cost <- my.df$delta.pci / my.df$ExtendedCo
aggregate(delta.over.cost ~ PlanActivi, my.df, mean ) # Crack Seal is crazy cost efficient
# subset of the ones you would do the 1st year
biggest.bang <- my.df[which(my.df$delta.over.cost > 2),]
sum(biggest.bang$ExtendedCo)
# Here I model the age as a function of PCI based on the references below:
# It is an average of residential and arterial, but we can divide those later
# http://onlinepubs.trb.org/onlinepubs/conferences/2012/assetmgmt/presentations/Data-A-Ramirez-Flores-Chang-Albitres.pdf
# https://repository.tamu.edu/bitstream/handle/1969.1/ETD-TAMU-2009-05-317/DESHMUKH-THESIS.pdf?sequence=2
# http://www.mylongview.com/modules/showdocument.aspx?documentid=631
# PCI = 100 - (106/((ln(79/AGE))^(1/.48)))
my.df$est.years <- 79*(2.71828^(-9.37879/(100-my.df$OCI)^0.48))
plot(my.df$est.years, my.df$OCI)
my.df$last.paved <- 2012 - my.df$est.years
hist(my.df$last.paved) # I'm skeptical there are streets we have not paved since the 80s
# Subsets of the modeled data
curtatone <- my.df[which(my.df$last.paved > 2003),]
really.old <- my.df[which(my.df$last.paved < 1989),]
# test
plot(log(my.df$ExtendedCo), my.df$OCI)
plot(my.df$delta.over.cost, my.df$OCI) # checking cost-effectiveness
fit <- lm(my.df$delta.over.cost, my.df$OCI)
# To see where the bands begin and end
aggregate(OCI ~ PlanActivi, my.df, mean )
aggregate(OCI ~ PlanActivi, my.df, min )
aggregate(OCI ~ PlanActivi, my.df, max )
# Now model cost as a f(PCI) using logical tests:
# this averages differences between collectors and arterials
my.df$cost.per.sy <- ifelse((my.df$OCI > 67) & (my.df$OCI < 89), 1.8,
ifelse((my.df$OCI > 44) & (my.df$OCI < 67), 18.50,
ifelse((my.df$OCI > 23) & (my.df$OCI < 44), 83.50,
ifelse((my.df$OCI > 0) & (my.df$OCI < 23), 150,
ifelse(my.df$OCI > 89, 0, 360)))))
# Test
my.df$cost <- my.df$cost.per.sy * my.df$sy
my.df$cost <- my.df$cost.per.sy * my.df$sq.yd
View(my.df)
delta <- my.df$sq.yd - my.df$ExtendedCo
delta
hist(my.df$cost)
my.df$cost
plot(my.df$sq.yd , my.df$ExtendedCo)
plot(my.df$sq.yd , my.df$cost)
plot(my.df$cost , my.df$ExtendedCo)
fit <- lm(my.df$ExtendedCo ~ my.df$cost , data=my.df)
summary(fit) # show results
# Now model cost as a f(PCI) using logical tests:
# this averages differences between collectors and arterials
my.df$cost.per.sy <- ifelse((my.df$OCI > 67) & (my.df$OCI < 89), 1.8,
ifelse((my.df$OCI > 44) & (my.df$OCI < 67), 18.50,
ifelse((my.df$OCI > 23) & (my.df$OCI < 44), 83.50,
ifelse((my.df$OCI > 0) & (my.df$OCI < 23), 160,
ifelse(my.df$OCI > 89, 0, 360)))))
# Test
my.df$cost <- my.df$cost.per.sy * my.df$sq.yd
delta <- my.df$sq.yd - my.df$ExtendedCo
delta
fit <- lm(my.df$ExtendedCo ~ my.df$cost , data=my.df)
summary(fit) # show results
plot(my.df$cost , my.df$ExtendedCo)
my.df$cost.per.sy <- ifelse((my.df$OCI > 67) & (my.df$OCI < 89), 1.8,
ifelse((my.df$OCI > 44) & (my.df$OCI < 67), 18.50,
ifelse((my.df$OCI > 23) & (my.df$OCI < 44), 83.50,
ifelse((my.df$OCI > 0) & (my.df$OCI < 23), 150,
ifelse(my.df$OCI > 89, 0, 360)))))
# Test
plot(my.df$cost , my.df$ExtendedCo)
fit <- lm(my.df$ExtendedCo ~ my.df$cost , data=my.df)
summary(fit) # show results
plot(my.df$cost , my.df$OCI)
plot(my.df$ExtendedCo , my.df$OCI)
plot(my.df$cost.per.sy , my.df$OCI)
plot(my.df$cost, my.df$OCI)
my.df$cost.per.sq.yd <- my.df$ExtendedCo / my.df$sq.yd
my.df$cost.per.sq.yd = x
x = my.df$cost.per.sq.yd
x = my.df$cost.per.sq.yd
y = oci
plot(x,y)
y = my.df$OCI
plot(x,y)
# I think one possible specification would be a cubic linear model
y.hat <- predict(lm(y~x+I(x^2)+I(x^3), data=d))
library("ggplot2")
qplot(x, y, data=d, geom="line") # your plot black lines
last_plot() + geom_line(aes(x=x, y=y.hat), col=2) # the fitted values red lines
y.hat <- predict(lm(y~x+I(x^2)+I(x^3)))
library("ggplot2")
qplot(x, y, geom="line") # your plot black lines
last_plot() + geom_line(aes(x=x, y=y.hat), col=2) # the fitted values red lines
summary(y.hat)
y.hat
summary(y.hat)
coefficients(y.hat)
coef(y.hat)
#fit first degree polynomial equation:
fit  <- lm(y~x)
#second degree
fit2 <- lm(y~poly(x,2,raw=TRUE))
#third degree
fit3 <- lm(y~poly(x,3,raw=TRUE))
#fourth degree
fit4 <- lm(y~poly(x,4,raw=TRUE))
#generate range of 50 numbers starting from 30 and ending at 160
xx <- seq(30,160, length=50)
plot(x,y,pch=19,ylim=c(0,150))
lines(xx, predict(fit, data.frame(x=xx)), col="red")
lines(xx, predict(fit2, data.frame(x=xx)), col="green")
lines(xx, predict(fit3, data.frame(x=xx)), col="blue")
lines(xx, predict(fit4, data.frame(x=xx)), col="purple")
# Better yet, use the empirical distribution
y = my.df$cost.per.sq.yd
x = my.df$OCI
plot(x,y)
#fit first degree polynomial equation:
fit  <- lm(y~x)
#second degree
fit2 <- lm(y~poly(x,2,raw=TRUE))
#third degree
fit3 <- lm(y~poly(x,3,raw=TRUE))
#fourth degree
fit4 <- lm(y~poly(x,4,raw=TRUE))
#generate range of 50 numbers starting from 30 and ending at 160
xx <- seq(0,160, length=50)
plot(x,y,pch=19,ylim=c(0,150))
lines(xx, predict(fit, data.frame(x=xx)), col="red")
lines(xx, predict(fit2, data.frame(x=xx)), col="green")
lines(xx, predict(fit3, data.frame(x=xx)), col="blue")
lines(xx, predict(fit4, data.frame(x=xx)), col="purple")
coef(fit4)
coef(fit4)
cost <- 1.845730e+00 *my.df$OCI^4 + 1.351524e+02
cost <- 1.845730e+00 * my.df$OCI^4 + -1.630135e-01 * my.df$OCI^3 + 2.195987e-03 * my.df$OCI^2 + -8.857414e-06 * my.df$OCI + 1.351524e+02
my.df$cost.model <- 1.845730e+00 * my.df$OCI^4 + -1.630135e-01 * my.df$OCI^3 + 2.195987e-03 * my.df$OCI^2 + -8.857414e-06 * my.df$OCI + 1.351524e+02
my.df$cost.model <- 1.845730e+00 * my.df$OCI^4 + -1.630135e-01 *
my.df$OCI^3 + 2.195987e-03 * my.df$OCI^2 + -8.857414e-06 * my.df$OCI + 1.351524e+02
plot(my.df$cost.model,my.df$cost.per.sq.yd)
fit <- lm(my.df$cost.model,my.df$cost.per.sq.yd)
summary(fit) # show results
plot(my.df$cost.model,my.df$cost.per.sq.yd)
hist(my.df$cost.model)
####  Better yet, use the empirical distribution ####
y = my.df$cost.per.sq.yd
x = my.df$OCI
plot(x,y)
#fit first degree polynomial equation:
fit  <- lm(y~x)
#second degree
fit2 <- lm(y~poly(x,2,raw=TRUE))
#third degree
fit3 <- lm(y~poly(x,3,raw=TRUE))
#fourth degree
fit4 <- lm(y~poly(x,4,raw=TRUE))
#generate range of 50 numbers starting from 30 and ending at 160
xx <- seq(0,160, length=50)
plot(x,y,pch=19,ylim=c(0,150))
lines(xx, predict(fit, data.frame(x=xx)), col="red")
lines(xx, predict(fit2, data.frame(x=xx)), col="green")
lines(xx, predict(fit3, data.frame(x=xx)), col="blue")
lines(xx, predict(fit4, data.frame(x=xx)), col="purple") ## This looks like the best fit
#y=ax^4 + bx^3 + cx^2 + dx + e
coef(fit4)
